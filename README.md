### 实现CART一元回归树
---
1. 理解： CART只要充分训练（有足够的分支和深度），能够完全拟合训练集，但是很明显会出现过拟合的情况，因为CART的拟合能力太强，我们没有对其加以限制。
2. 为了避免CART的过拟合影响，我们可以通过集成学习的思路来减缓过拟合带来的影响，一个思路是bagging方法，对应的是随机森林算法，一个思路是boosting算法，对应的是boosting tree，基于CART为子树的回归算法，可以演化出gbdt，对于工程化实现，演变出了xgboost以及lightGBM算法。
3. random forest：随机森林属于集成方法中的bagging方法，我们可以并行训练多个拟合能力很强的CART树，然后进行average（回归）或者vote（分类），通过减小方差来一定程度上缓解过拟合，类比神经网络中的dropout方法。
4. 提升树系列算法：提升树系列算法属于继承方法中的boosting方法，我们通过组合多个弱分类器，来得到一个强分类器，思想是串行训练每个模型，后面的模型去拟合前面模型的残差（损失函数为mse的特殊情况），通过减小偏差，最终得到一个拟合能力较好的模型。由于是通过减小偏差，那么会出现过拟合的情况。

### 试验
---
在多个子CART树串行的情况下，模型确实能够随着子树数目的增长逐渐拟合训练集。即使每个子树的高度限制为2，通过串行的方式，也能够完全拟合训练集。

